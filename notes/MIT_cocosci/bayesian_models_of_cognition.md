# Bayesian Models of Cognition

### Summary

This is a high-detail survey of current methods in modern hierarchical bayesian architectures, as used in the other papers by Tenenbaum's group.  
It is difficult to summarize here, but if you're seeking to understand the math behind these systems, this is the place to look.  

Here are the sections of the paper:
- 1: Introduction and context for the rest of the paper
- 2: Basic Bayes rule and modifications of it. Motivation is allowing learning from sparse data.
- 3: (Causal) Graphical models, generative models, hidden markov models: the start of heirarchy
- 4: Heirarchical Bayesian models. Multiple levels allows sharing knowledge across distinct domains. 
- 5: Markov chain monte carlo. Stochastic methods for computing Bayesian models

### Hypotheses

Heirarchical Bayesian models can describe some functions of human cognition. This paper lays the groundwork mathematics for this hypothesis to be tested.

### Methods 

Math.

### Results

N/A

### Discussion

N/A

### Takeaways:

If any Bayesian techniques were ever going to make their way into FARG (Which I'm not sure they should), then this would be the place to start.  
Either way, this paper is great context for understanding the other models.

### Citation:

```
@article{bayesian-models-of-cognition,
    author  = "Griffiths, Thomas L.; Kemp, Charles.; Tenenbaum, Joshua B.",
    title   = "Bayesian Models of Cognition",
    journal = "",
    volume  = "",
    number  = "",
    pages   = "",
    year    = "2008",
    url     = "https://cocosci.berkeley.edu/tom/papers/bayeschapter.pdf"
}
```
