# Agents and Agencies

Technically, the majority of the book is agents/agencies. Better shove all my notes into this single file.

### Agents

Agents, despite sometimes being discussed otherwise, are essentially equivalent to codelets. In the Society of Mind architecture, agents are the independent pieces that the whole is built from. Of particular interest is the ways that these parts of combined -- as this is what gives meaning to the emergent structure. In fact, the entirety of Society of Mind is simply discussing either kinds of agents, or methods for organizing them.

"We can only explain the mind in terms of things that have no thoughts or feelings of their own, otherwise we'll have gone in a circle" (18)

Read this in the context (if you didn't already know) that Marvin Minsky considers common sense the most important part of thinking:  
"Common sense is not a simple thing. Instead, it is an immense _society_ of hard-earned practical ideas -- of multitudes of life-learned rules and exceptions, dispositions and tendencies, balances and checks" (22).

Minsky will later apply this to several other ideas. Essentially, most things in the mind are composed of smaller parts. Who could disagree with that?

### Agencies

"It is not enough to explain only what each separate agent does. We must also understand how these parts are interrelated -- that is, how groups of agents can accomplish things" (23).

Agency-agents simply turn smaller agents on and off, the same way that neurons excite or inhibit. However, most composite agencies do not have comprehension.

See 2.3 and 2.4 as well:

"The mind still holds its mystery, because we know so little about how mental agents _interact_ to accomplish the things that they do" (28).

On heterarchies (3.4):
"[Loops] are impossible in simple heirarchies.. Later we'll see more cross-connected rings and loops -- when we are forced to consider the need for memory, which will become a constant object of concern in this book... If we have enough memory, we can arrange our agents into circular loops and thus use the same agents over and over again to do parts of different jobs at the same time" (35).

"We're always enmeshed in causal loops" (48). 

"You can never find a final cause, since you must always ask one question more: 'What caused this cause?'" (49). However, "Circular thinking can lead to growth when it results, at each return, in deeper and more powerful ideas" (49). 

Some restatements:

"To get a good idea, one must engage huge organizations of submachines that do a vast variety of jobs" (66)

"Each specialized agency must learn to call on other specialists that can serve its purposes. Certain sections of the brain distinguish the sights of faces from other types of objects. No one knows how many different such organs lie in our brains. But it is almost certain that they all employ somewhat different types of programming and forms of representation: they share no common language code" (66). Quite the claim here.. _nothing_ is shared? This is worth debating.


